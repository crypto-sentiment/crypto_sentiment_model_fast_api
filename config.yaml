data:
  path_to_data: data                          # Local path where the train and validation data should be placed
                                              # in order to run the model training
  train_filename: toy_train.csv     # Filename of the training data
  text_field_name: title
  label_field_name: sentiment
  num_classes: 3
  max_text_length_words: 500
  class_names: ["Negative", "Neutral", "Positive"]

cross_validation:                             # Params of cross-validation
  cv_perform_cross_val: true                  # Whether to perform cross-validation
  cv_n_splits: 5
  cv_shuffle: true
  cv_random_state: 17
  cv_n_jobs: 4
  cv_scoring: accuracy                        # Scoring name compatible with Sklearn

model:                                        # Params of the model defined in src/model.py
  name: "Tf-Idf & logreg"                     # TODO replace this with setting up MLFlow tracking
  version: 0.1.0                              # TODO replace this with setting up MLFlow tracking
  path_to_model: static/models/logit_tfidf_btc_sentiment.pkl # TODO replace this with setting up MLFlow tracking
  tfidf: # See https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html
    stop_words: english
    ngram_range: '(1, 5)'
    analyzer: char
    min_df: 8
    lowercase: true
    max_features: 100000
  logreg: # See https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html
    C: 2.7
    solver: lbfgs
    multi_class: multinomial
    random_state: 17
    max_iter: 500
    n_jobs: 4
    fit_intercept: false

logging:
  version: 1
  formatters:
    app:
      format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
  handlers:
    console:
      class: logging.StreamHandler
      level: INFO
      formatter: app
      stream: ext://sys.stdout
  loggers:
    appLogger:
      level: INFO
      handlers: [console]
      propagate: no
  root:
    level: INFO
    handlers: [console]
